# Multimodal Action Recognition

Project done for the Advanced Machine Learning course at Politecnico di Torino, by Nunzio Messineo with the collaboration of Federico Buccellato and Raffaele Viola, started from a given base project.

This project explores action recognition using two modalities: standard visual data (RGB streams) and ElectroMyoGraphy (EMG). The initial phase focuses on analyzing first-person perspective RGB data using a state-of-the-art action recognition algorithm. The next phase introduces EMG, a lesser-explored modality in computer vision, to investigate its potential in enhancing action classification. By combining visual and muscle activity data, the project aims to develop a more comprehensive understanding of human actions and improve recognition performance in challenging scenarios.

For more information read the [paper](https://github.com/Nunziojh/MultimodalActionRecognition/blob/main/paper.pdf)

Here there are the slides of the [presentation](https://www.canva.com/design/DAGQYb7wKdw/A_3D7ZRhG1OQV0yqkcgOAw/edit?utm_content=DAGQYb7wKdw&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton).
